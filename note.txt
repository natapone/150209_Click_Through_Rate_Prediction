Click-Through Rate Prediction
http://www.kaggle.com/c/avazu-ctr-prediction


File descriptions
* train - Training set. 10 days of click-through data, ordered chronologically. Non-clicks and clicks are subsampled according to different strategies.
* test - Test set. 1 day of ads to for testing your model predictions. 
* sampleSubmission.csv - Sample submission file in the correct format, corresponds to the All-0.5 Benchmark.

Data fields
* id: ad identifier
* click: 0/1 for non-click/click
* hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.
* C1 -- anonymized categorical variable
* banner_pos
* site_id
* site_domain
* site_category
* app_id
* app_domain
* app_category
* device_id
* device_ip
* device_model
* device_type
* device_conn_type
* C14-C21 -- anonymized categorical variables

=========
How data create? (assuming)

Click/non-click records are subsampled based on different sampling strategies. We have subsampled much fewer non-click records, which makes the CTR really high.


Data Cleanup ideas
* split web and mobile ads (site_domain/app_domain)

* replace low frequency with “RARE”
	- apply to category (add, domain)
	- be able to handle out of sample error
	- will fix: site_category, app_domain, app_category

* Size of web influent	CTR e.g. Amazon, Google
	- count site_domain in log scale, call as “Traffic level”, remove site_domain
* User activity influent CTR on some type of site
	- assume that userid with difference ip in same timeframe is moveing
	- Count IP of same (user + time) if > 1 = “IS_MOVING”, remove user id
* generalize data
	- remove “_id”, “_ip”



=========
# http://stackoverflow.com/questions/1727772/quickly-reading-very-large-tables-as-dataframes-in-r/15058684#15058684

# validate ==> 
# http://stat.ethz.ch/R-manual/R-patched/library/stats/html/aggregate.html
# http://stats.stackexchange.com/questions/8225/how-to-summarize-data-by-group-in-r
# data test without train => http://stackoverflow.com/questions/7719741/how-to-test-if-list-element-exists
# compare lists => http://stackoverflow.com/questions/17598134/compare-two-lists-in-r

# Convert
# Round time => convert to xxxx0000
# convert to time => http://stackoverflow.com/questions/13456241/convert-unix-epoch-to-date-object-in-r

# List unique values
# unique(tr$banner_pos)

# Misc
# class, ncol, colnames, remove

# Model
# Hidden Markov model, Naive Bayes classifier

# select data.table by multiple columns
test_set[,c("id","C1"),with=FALSE]

# From ?data.table:
# When with=FALSE, j is a vector of names or positions to select, similar to a data.frame. with=FALSE is often useful in data.table to select columns dynamically.

save_model <- function (hm_model, file = "set_100_model.RData") {
    saveRDS(m, file)
}

load_model <- function (file = "set_100_model.RData") {
    m <- readRDS(file)
    m
}


# Plot
> qplot(click,colour=banner_pos,data=train_set,geom="density")
> qplot(banner_pos,site_category,colour=click,data=train_set)

# Aggregate
> aggregate(train_set$click, list(train_set$banner_pos), mean  )
> agg = aggregate(training$C1, list(training$C1), length  )

# Aggregate average and count
> aggregate(training$click, list(training$banner_pos, training$device_conn_type), 
          FUN=function(x) c(mn =mean(x), c=length(x) ))

#determining memory usage
#http://stackoverflow.com/questions/1395270/determining-memory-usage
sort( sapply(ls(),function(x){object.size(get(x))}))

# Speedup save and load data
http://stackoverflow.com/questions/11559628/speed-up-rdata-load
system.time(saveRDS(train_set,file=“train_set_full.RData",compress=F))

# transform classes to multiple columns
> ?dummyVars

# ===> normal use
when <- data.frame(time = c("afternoon", "night", "afternoon",
                            "morning", "morning", "morning",
                            "morning", "afternoon", "afternoon"),
                   day = c("Mon", "Mon", "Mon",
                           "Wed", "Wed", "Fri",
                           "Sat", "Sat", "Fri"))

levels(when$time) <- c("morning", "afternoon", "night")
levels(when$day) <- c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")

## Default behavior:
model.matrix(~day, when)

#——
t[t$.outcome == 1]
predictions <- predict(modelFit,newdata= testing[testing$click == 1])

inTrain = createDataPartition(y=data$click, p=0.1, list=FALSE, time = 10)
inTrain[,3]

